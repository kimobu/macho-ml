{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "blank-marker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"Opens JSON files of Mach-O data and aggregates into a single pandas dataframe, saving as a CSV.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--path\",\n",
    "    default=\"./json_data\",\n",
    "    type=str,\n",
    "    help=\"Where to look for parsed JSON files.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--outdir\",\n",
    "    default=\"/tmp/json_data\",\n",
    "    type=str,\n",
    "    help=\"Where to output the CSV.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--outfile\",\n",
    "    default=\"macho_feature_vector.csv\",\n",
    "    type=str,\n",
    "    help=\"What to call the CSV file.\",\n",
    ")\n",
    "args = parser.parse_args()\n",
    "\"\"\"\n",
    "\n",
    "def load_json(filename: str) -> str:\n",
    "    with open(filename, \"r\") as f:\n",
    "        data = json.loads(f.read())\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_files(path: str) -> list:\n",
    "    filelist = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            fullpath = os.path.join(root, filename)\n",
    "            filelist.append(fullpath)\n",
    "    return filelist\n",
    "\n",
    "\n",
    "def parse_segment(load_command: object):\n",
    "    segment = {}\n",
    "    name = load_command[\"name\"]\n",
    "    segment[\"name\"] = name\n",
    "    segment[f\"segment_{name}_vmsize\"] = load_command[\"vmsize\"]\n",
    "    segment[f\"segment_{name}_size\"] = load_command[\"size\"]\n",
    "    segment[f\"segment_{name}_initprot\"] = load_command[\"initprot\"]\n",
    "    segment[f\"segment_{name}_maxprot\"] = load_command[\"maxprot\"]\n",
    "    segment[f\"segment_{name}_nsects\"] = load_command[\"nsects\"]\n",
    "    segment[f\"segment_{name}_entropy\"] = load_command[\"entropy\"]\n",
    "    for sect in load_command[\"sects\"]:\n",
    "        sectname = sect[\"name\"]\n",
    "        segment[f\"segment_{name}_{sectname}\"] = sect\n",
    "    return segment\n",
    "\n",
    "\n",
    "def parse_loaddylib(load_command: object, mach: object):\n",
    "    dylib = {}\n",
    "    name = load_command[\"name\"]\n",
    "    dylib[\"name\"] = name\n",
    "    if \"imports\" in mach[\"macho\"].keys():\n",
    "        for imp in mach[\"macho\"][\"imports\"]:\n",
    "            if imp[1] == name:\n",
    "                impfunc = imp[0]\n",
    "                dylib[f\"dylib_{name}_{impfunc}\"] = 1            \n",
    "\n",
    "    dylib[f\"dylib_{name}_cmdsize\"] = load_command[\"cmd_size\"]\n",
    "    dylib[f\"dylib_{name}_version\"] = load_command[\"current_version\"]\n",
    "    dylib[f\"dylib_{name}_timestamp\"] = load_command[\"timestamp\"]\n",
    "    return dylib\n",
    "\n",
    "\n",
    "def parse_json(data: object, filename: str):\n",
    "    mach = {}\n",
    "    mach[\"name\"] = data[\"name\"]\n",
    "    mach[\"size\"] = data[\"size\"]\n",
    "    mach[\"entropy\"] = data[\"entropy\"]\n",
    "    mach[\"nlcs\"] = data[\"macho\"][\"nlcs\"]\n",
    "    mach[\"slcs\"] = data[\"macho\"][\"slcs\"]\n",
    " \n",
    "    for flag in data[\"macho\"][\"flags\"]:\n",
    "        name = f\"flag_{flag}\"\n",
    "        mach[name] = 1\n",
    "    if \"packed\" in filename:\n",
    "        mach[\"packed\"] = 1\n",
    "    else:\n",
    "        mach[\"packed\"] = 0\n",
    "    if data[\"malware\"] == 1:\n",
    "        mach[\"malware\"] = 1\n",
    "    else:\n",
    "        mach[\"malware\"] = 0\n",
    "    for load_command in data[\"macho\"][\"lcs\"]:\n",
    "        lc_type = load_command[\"cmd\"]\n",
    "        if lc_type == \"SEGMENT\" or lc_type == \"SEGMENT_64\":\n",
    "            segment = parse_segment(load_command)\n",
    "            name = segment[\"name\"]\n",
    "            mach[f\"segment_{name}\"] = 1\n",
    "            for k,v in segment.items():\n",
    "                mach[f\"{k}\"] = v\n",
    "        if lc_type == \"LOAD_DYLIB\":\n",
    "            dylib = parse_loaddylib(load_command, data)\n",
    "            name = dylib[\"name\"]\n",
    "            mach[f\"dylib_{name}\"] = 1\n",
    "            for k,v in dylib.items():\n",
    "                mach[f\"{k}\"] = v\n",
    "    return mach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "threaded-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_parse(files, malware=0):\n",
    "    global machos \n",
    "    global max_len \n",
    "    global keys \n",
    "\n",
    "    for file in files:\n",
    "        toparse = []\n",
    "        with open(file, \"r\") as f:\n",
    "            jsondata = json.loads(f.read())\n",
    "            if \"universal\" in jsondata.keys():\n",
    "                for arch in jsondata[\"universal\"][\"machos\"]:\n",
    "                    jsondata[\"macho\"] = arch\n",
    "                    jsondata['malware'] = malware\n",
    "                    toparse.append(jsondata)\n",
    "            else:\n",
    "                jsondata['malware'] = malware\n",
    "                toparse.append(jsondata)\n",
    "        for macho in toparse:\n",
    "            mach = parse_json(macho, file)\n",
    "            if not mach:\n",
    "                print(f\"failed {file}\")\n",
    "                continue\n",
    "            machos.append(mach)\n",
    "            [keys.append(x) for x in mach.keys()]\n",
    "            cur_len = len(mach)\n",
    "            if cur_len > max_len:\n",
    "                max_len = cur_len\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "machos = []\n",
    "max_len = 0\n",
    "keys = []\n",
    "\n",
    "files = get_files(\"json_benign\")\n",
    "call_parse(files)\n",
    "# Repeat, but with malware. Mark malware in JSON\n",
    "files = get_files(\"json_malware\")\n",
    "call_parse(files, malware=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=set(keys))\n",
    "count = 0\n",
    "for mach in machos:\n",
    "    df.loc[count] = 0  # Initializes all values for the ID to zero.\n",
    "    df.loc[count, mach] = 1  # Sets relevant features to a value of one.\n",
    "    df.loc[count]['name'] = mach['name']\n",
    "    df.loc[count]['size'] = mach['size'] # update non-binary columns\n",
    "    df.loc[count]['entropy'] = mach['entropy']\n",
    "    df.loc[count]['nlcs'] = mach['nlcs']\n",
    "    df.loc[count]['slcs'] = mach['slcs']\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every column is an object. Iterate the column and set to appropriate types\n",
    "for column in df.columns:\n",
    "    a = df[column].describe()\n",
    "    df[column] = df[column].astype(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-edwards",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-notebook",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "#Select top 2 features based on mutual info regression\n",
    "X = df.drop(['packed','name','malware'], axis=1)\n",
    "y = df['packed']\n",
    "selector = SelectKBest(mutual_info_regression, k=200)\n",
    "selector.fit(X, y)\n",
    "X.columns[selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X.columns[selector.get_support()]:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if \"upx\" in column:\n",
    "        print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"segment_upxTEXT\"]==1][\"segment_upxTEXT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = {'name': '__TEXT', 'segment___TEXT_vmsize': 167936, 'segment___TEXT_size': 632, 'segment___TEXT_initprot': 'r-x', 'segment___TEXT_maxprot': 'r-x', 'segment___TEXT_nsects': 7, 'segment___TEXT_entropy': 0.7824717353762201}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in test.items():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-merchant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
